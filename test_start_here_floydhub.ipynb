{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On Building a Deep Learning Dataset Using Social Media Images and Training a Model to Detect Street Art\n",
    "\n",
    "Here’s a quick overview of our process:\n",
    "        \n",
    "\n",
    "1. Build a street art deep learning image dataset using hashtag results for “#streetart”.\n",
    "2. Use the images to build a model that will predict if images contain street art.\n",
    "3. Clean the dataset and retrain the model for improved results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T14:31:52.077648Z",
     "start_time": "2019-01-24T14:31:50.973834Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "from imutils import build_montages\n",
    "from imutils import paths\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from pyimagesearch.resnet import ResNet\n",
    "from sklearn.metrics import classification_report\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T14:31:52.303990Z",
     "start_time": "2019-01-24T14:31:52.243773Z"
    }
   },
   "outputs": [],
   "source": [
    "PATH = 'streetart'\n",
    "\n",
    "# initialize the number of training epochs and batch size\n",
    "DATASET = 'streetart/images'\n",
    "NUM_EPOCHS = 50\n",
    "BS = 32\n",
    "IMAGE_NAME = 'plot.png'\n",
    "MODEL_NAME = 'streetart.model'\n",
    "# derive the path to the directories containing the training,\n",
    "# validation, and testing splits, respectively\n",
    "\n",
    "TRAIN_PATH = os.path.sep.join([DATASET, \"training\"])\n",
    "VAL_PATH = os.path.sep.join([DATASET, \"validation\"])\n",
    "TEST_PATH = os.path.sep.join([DATASET, \"testing\"])\n",
    "\n",
    "MONTAGE_FILENAME = 'streetart_montage.png'\n",
    "imagePaths = list(paths.list_images(TEST_PATH))\n",
    "random.shuffle(imagePaths)\n",
    "imagePaths = imagePaths[:50]\n",
    "\n",
    "# initialize our list of results\n",
    "results = []\n",
    "\n",
    "# determine the total number of image paths in training, validation,\n",
    "# and testing directories\n",
    "totalTrain = len(list(paths.list_images(TRAIN_PATH)))\n",
    "totalVal = len(list(paths.list_images(VAL_PATH)))\n",
    "totalTest = len(list(paths.list_images(TEST_PATH)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T12:04:52.433887Z",
     "start_time": "2019-01-24T12:04:52.281601Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'streetart/images/training'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-f768a1960a89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mcolor_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"rgb\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \tbatch_size=32)\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# initialize the validation generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tf_gpu/lib/python3.6/site-packages/keras_preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[1;32m   1011\u001b[0m             \u001b[0mfollow_links\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_links\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m             \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m             interpolation=interpolation)\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m     def flow_from_dataframe(self, dataframe, directory,\n",
      "\u001b[0;32m~/anaconda2/envs/tf_gpu/lib/python3.6/site-packages/keras_preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m   1873\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1874\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1875\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1876\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1877\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'streetart/images/training'"
     ]
    }
   ],
   "source": [
    "# initialize the training training data augmentation object\n",
    "trainAug = ImageDataGenerator(\n",
    "\trescale=1 / 255.0,\n",
    "\trotation_range=20,\n",
    "\tzoom_range=0.05,\n",
    "\twidth_shift_range=0.05,\n",
    "\theight_shift_range=0.05,\n",
    "\tshear_range=0.05,\n",
    "\thorizontal_flip=True,\n",
    "\tfill_mode=\"nearest\")\n",
    "\n",
    "# initialize the validation (and testing) data augmentation object\n",
    "valAug = ImageDataGenerator(rescale=1 / 255.0)\n",
    "\n",
    "# initialize the training generator\n",
    "trainGen = trainAug.flow_from_directory(\n",
    "\tTRAIN_PATH,\n",
    "\tclass_mode=\"categorical\",\n",
    "\ttarget_size=(64, 64),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=True,\n",
    "\tbatch_size=32)\n",
    "\n",
    "# initialize the validation generator\n",
    "valGen = valAug.flow_from_directory(\n",
    "\tVAL_PATH,\n",
    "\tclass_mode=\"categorical\",\n",
    "\ttarget_size=(64, 64),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=False,\n",
    "\tbatch_size=BS)\n",
    "\n",
    "# initialize the testing generator\n",
    "testGen = valAug.flow_from_directory(\n",
    "\tTEST_PATH,\n",
    "\tclass_mode=\"categorical\",\n",
    "\ttarget_size=(64, 64),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=False,\n",
    "\tbatch_size=BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T12:04:52.438052Z",
     "start_time": "2019-01-24T12:04:51.126Z"
    }
   },
   "outputs": [],
   "source": [
    "# initialize our Keras implementation of ResNet model and compile it\n",
    "model = ResNet.build(64, 64, 3, 2, (2, 2, 3),\n",
    "\t(32, 64, 128, 256), reg=0.0005)\n",
    "opt = SGD(lr=1e-1, momentum=0.9, decay=1e-1 / NUM_EPOCHS)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "\n",
    "# train our Keras model\n",
    "H = model.fit_generator(\n",
    "\ttrainGen,\n",
    "\tsteps_per_epoch=totalTrain // BS,\n",
    "\tvalidation_data=valGen,\n",
    "\tvalidation_steps=totalVal // BS,\n",
    "\tepochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T12:04:52.440293Z",
     "start_time": "2019-01-24T12:04:51.126Z"
    }
   },
   "outputs": [],
   "source": [
    "# reset the testing generator and then use our trained model to\n",
    "# make predictions on the data\n",
    "print(\"[INFO] evaluating network...\")\n",
    "testGen.reset()\n",
    "predIdxs = model.predict_generator(testGen,\n",
    "\tsteps=(totalTest // BS) + 1)# for each image in the testing set we need to find the index of the\n",
    "# label with corresponding largest predicted probability\n",
    "predIdxs = np.argmax(predIdxs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T12:04:52.442432Z",
     "start_time": "2019-01-24T12:04:51.127Z"
    }
   },
   "outputs": [],
   "source": [
    "print(predIdxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T12:04:52.444732Z",
     "start_time": "2019-01-24T12:04:51.128Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# show a nicely formatted classification report\n",
    "print(classification_report(testGen.classes, predIdxs, target_names=testGen.class_indices.keys()))\n",
    "\n",
    "# save the network to disk\n",
    "print(\"[INFO] serializing network to '{}'...\".format(MODEL_NAME))\n",
    "model.save(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T12:04:52.445682Z",
     "start_time": "2019-01-24T12:04:51.129Z"
    }
   },
   "outputs": [],
   "source": [
    "model = load_model(MODEL_NAME)\n",
    "\n",
    "# loop over our sampled image paths\n",
    "print(\"[INFO] evaluating model against test set...\")\n",
    "for p in imagePaths:\n",
    "\t# load our original input image\n",
    "\torig = cv2.imread(p)\n",
    "\n",
    "\t# pre-process our image by converting it from BGR to RGB channel\n",
    "\t# ordering (since our Keras mdoel was trained on RGB ordering),\n",
    "\t# resize it to 64x64 pixels, and then scale the pixel intensities\n",
    "\t# to the range [0, 1]\n",
    "\timage = cv2.cvtColor(orig, cv2.COLOR_BGR2RGB)\n",
    "\timage = cv2.resize(image, (64, 64))\n",
    "\timage = image.astype(\"float\") / 255.0\n",
    "\n",
    "\t# order channel dimensions (channels-first or channels-last)\n",
    "\t# depending on our Keras backend, then add a batch dimension to\n",
    "\t# the image\n",
    "\timage = img_to_array(image)\n",
    "\timage = np.expand_dims(image, axis=0)\n",
    "\n",
    "\t# make predictions on the input image\n",
    "\tpred = model.predict(image)\n",
    "\tpred = pred.argmax(axis=1)[0]\n",
    "\n",
    "\t# an index of zero is the 'parasitized' label while an index of\n",
    "\t# one is the 'uninfected' label\n",
    "\tlabel = \"Not street art\" if pred == 0 else \"Street art found\"\n",
    "\tcolor = (255, 0, 0) if pred == 0 else (0, 255, 0)\n",
    "\n",
    "\t# resize our original input (so we can better visualize it) and\n",
    "\t# then draw the label on the image\n",
    "\torig = cv2.resize(orig, (128, 128))\n",
    "\tcv2.putText(orig, label, (3, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "\t\tcolor, 2)\n",
    "\n",
    "\t# add the output image to our list of results\n",
    "\tresults.append(orig)\n",
    "print(\"[INFO] building image montage of results...\")\n",
    "\n",
    "# create a montage using 128x128 \"tiles\" with 4 rows and 4 columns\n",
    "montage = build_montages(results, (200, 200), (5, 10))[0]\n",
    "cv2.imwrite(MONTAGE_FILENAME, montage)\n",
    "\n",
    "img = cv2.imread(MONTAGE_FILENAME)\n",
    "img2 = img[:,:,::-1]\n",
    "plt.imshow(img)\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(filename=MONTAGE_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
