{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-21T21:53:37.172458Z",
     "start_time": "2019-01-21T21:53:36.304722Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# USAGE\n",
    "# Start the server:\n",
    "# \tpython run_keras_server.py\n",
    "# Submit a request via cURL:\n",
    "# \tcurl -X POST -F image=@jemma.png 'http://localhost:5000/predict'\n",
    "# Submita a request via Python:\n",
    "#\tpython simple_request.py \n",
    "\n",
    "# import the necessary packages\n",
    "from keras.applications import ResNet50\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.models import load_model\n",
    "from threading import Thread\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import base64\n",
    "import flask\n",
    "import redis\n",
    "import uuid\n",
    "import time\n",
    "import json\n",
    "import sys\n",
    "import io\n",
    "\n",
    "# initialize constants used to control image spatial dimensions and\n",
    "# data type\n",
    "IMAGE_WIDTH = 224\n",
    "IMAGE_HEIGHT = 224\n",
    "IMAGE_CHANS = 3\n",
    "IMAGE_DTYPE = \"float32\"\n",
    "MODEL_PATH = '../streetart_model.model'\n",
    "\n",
    "# initialize constants used for server queuing\n",
    "IMAGE_QUEUE = \"image_queue\"\n",
    "BATCH_SIZE = 32\n",
    "SERVER_SLEEP = 0.25\n",
    "CLIENT_SLEEP = 0.25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-21T21:53:46.550150Z",
     "start_time": "2019-01-21T21:53:46.543709Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# initialize our Flask application, Redis server, and Keras model\n",
    "app = flask.Flask(__name__)\n",
    "db = redis.StrictRedis(host=\"localhost\", port=6379, db=0)\n",
    "model = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-21T21:53:55.327242Z",
     "start_time": "2019-01-21T21:53:55.315600Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def base64_encode_image(a):\n",
    "\t# base64 encode the input NumPy array\n",
    "\treturn base64.b64encode(a).decode(\"utf-8\")\n",
    "\n",
    "def base64_decode_image(a, dtype, shape):\n",
    "\t# if this is Python 3, we need the extra step of encoding the\n",
    "\t# serialized NumPy string as a byte object\n",
    "\tif sys.version_info.major == 3:\n",
    "\t\ta = bytes(a, encoding=\"utf-8\")\n",
    "\n",
    "\t# convert the string to a NumPy array using the supplied data\n",
    "\t# type and target shape\n",
    "\ta = np.frombuffer(base64.decodestring(a), dtype=dtype)\n",
    "\ta = a.reshape(shape)\n",
    "\n",
    "\t# return the decoded image\n",
    "\treturn a\n",
    "\n",
    "def prepare_image(image, target):\n",
    "\t# if the image mode is not RGB, convert it\n",
    "\tif image.mode != \"RGB\":\n",
    "\t\timage = image.convert(\"RGB\")\n",
    "\n",
    "\t# resize the input image and preprocess it\n",
    "\timage = image.resize(target)\n",
    "\timage = img_to_array(image)\n",
    "\timage = np.expand_dims(image, axis=0)\n",
    "\timage = imagenet_utils.preprocess_input(image)\n",
    "\n",
    "\t# return the processed image\n",
    "\treturn image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-21T21:58:01.744633Z",
     "start_time": "2019-01-21T21:58:01.727413Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def classify_process():\n",
    "\t# load the pre-trained Keras model (here we are using a model\n",
    "\t# pre-trained on ImageNet and provided by Keras, but you can\n",
    "\t# substitute in your own networks just as easily)\n",
    "\tprint(\"* Loading model...\")\n",
    "\tmodel = ResNet50(weights=\"imagenet\")\n",
    "\t# model = load_model(MODEL_PATH)\n",
    "\tprint(\"* Model loaded\")\n",
    "\n",
    "\t# continually pool for new images to classify\n",
    "\twhile True:\n",
    "\t\t# attempt to grab a batch of images from the database, then\n",
    "\t\t# initialize the image IDs and batch of images themselves\n",
    "\t\tqueue = db.lrange(IMAGE_QUEUE, 0, BATCH_SIZE - 1)\n",
    "\t\timageIDs = []\n",
    "\t\tbatch = None\n",
    "\n",
    "\t\t# loop over the queue\n",
    "\t\tfor q in queue:\n",
    "\t\t\t# deserialize the object and obtain the input image\n",
    "\t\t\tq = json.loads(q.decode(\"utf-8\"))\n",
    "\t\t\timage = base64_decode_image(q[\"image\"], IMAGE_DTYPE,\n",
    "\t\t\t\t(1, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANS))\n",
    "\n",
    "\t\t\t# check to see if the batch list is None\n",
    "\t\t\tif batch is None:\n",
    "\t\t\t\tbatch = image\n",
    "\n",
    "\t\t\t# otherwise, stack the data\n",
    "\t\t\telse:\n",
    "\t\t\t\tbatch = np.vstack([batch, image])\n",
    "\n",
    "\t\t\t# update the list of image IDs\n",
    "\t\t\timageIDs.append(q[\"id\"])\n",
    "\n",
    "\t\t# check to see if we need to process the batch\n",
    "\t\tif len(imageIDs) > 0:\n",
    "\t\t\t# classify the batch\n",
    "\t\t\tprint(\"* Batch size: {}\".format(batch.shape))\n",
    "\t\t\tpreds = model.predict(batch)\n",
    "\t\t\tresults = imagenet_utils.decode_predictions(preds)\n",
    "\n",
    "\t\t\t# loop over the image IDs and their corresponding set of\n",
    "\t\t\t# results from our model\n",
    "\t\t\tfor (imageID, resultSet) in zip(imageIDs, results):\n",
    "\t\t\t\t# initialize the list of output predictions\n",
    "\t\t\t\toutput = []\n",
    "\n",
    "\t\t\t\t# loop over the results and add them to the list of\n",
    "\t\t\t\t# output predictions\n",
    "\t\t\t\tfor (imagenetID, label, prob) in resultSet:\n",
    "\t\t\t\t\tr = {\"label\": label, \"probability\": float(prob)}\n",
    "\t\t\t\t\toutput.append(r)\n",
    "\n",
    "\t\t\t\t# store the output predictions in the database, using\n",
    "\t\t\t\t# the image ID as the key so we can fetch the results\n",
    "\t\t\t\tdb.set(imageID, json.dumps(output))\n",
    "\n",
    "\t\t\t# remove the set of images from our queue\n",
    "\t\t\tdb.ltrim(IMAGE_QUEUE, len(imageIDs), -1)\n",
    "\n",
    "\t\t# sleep for a small amount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-21T21:58:06.465441Z",
     "start_time": "2019-01-21T21:58:06.436723Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-43d5ee9e5e6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# add the output predictions to our data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# dictionary so we can return it to the client\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"predictions\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "# read the image in PIL format and prepare it for\n",
    "# classification\n",
    "image = Image.open('../streetart_plot.png')\n",
    "image = prepare_image(image, (IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "\n",
    "# ensure our NumPy array is C-contiguous as well,\n",
    "# otherwise we won't be able to serialize it\n",
    "image = image.copy(order=\"C\")\n",
    "\n",
    "# generate an ID for the classification then add the\n",
    "# classification ID + image to the queue\n",
    "k = str(uuid.uuid4())\n",
    "d = {\"id\": k, \"image\": base64_encode_image(image)}\n",
    "db.rpush(IMAGE_QUEUE, json.dumps(d))\n",
    "\n",
    "# keep looping until our model server returns the output\n",
    "# predictions\n",
    "while True:\n",
    "    # attempt to grab the output predictions\n",
    "    output = db.get(k)\n",
    "\n",
    "    # check to see if our model has classified the input\n",
    "    # image\n",
    "    if output is not None:\n",
    "        # add the output predictions to our data\n",
    "        # dictionary so we can return it to the client\n",
    "        output = output.decode(\"utf-8\")\n",
    "        data[\"predictions\"] = json.loads(output)\n",
    "\n",
    "        # delete the result from the database and break\n",
    "        # from the polling loop\n",
    "        db.delete(k)\n",
    "        break\n",
    "\n",
    "    # sleep for a small amount to give the model a chance\n",
    "    # to classify the input image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-21T21:56:54.357667Z",
     "start_time": "2019-01-21T21:56:36.790Z"
    }
   },
   "outputs": [],
   "source": [
    "return flask.jsonify(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-21T21:58:20.588279Z",
     "start_time": "2019-01-21T21:58:20.583766Z"
    }
   },
   "outputs": [],
   "source": [
    "db.get(k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-21T21:58:25.900825Z",
     "start_time": "2019-01-21T21:58:25.893721Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "output = db.get(k)\n",
    "\n",
    "# check to see if our model has classified the input\n",
    "# image\n",
    "if output is not None:\n",
    "    # add the output predictions to our data\n",
    "    # dictionary so we can return it to the client\n",
    "    output = output.decode(\"utf-8\")\n",
    "    data[\"predictions\"] = json.loads(output)\n",
    "\n",
    "    # delete the result from the database and break\n",
    "    # from the polling loop\n",
    "    db.delete(k)\n",
    "\n",
    "    print(data)\n",
    "    \n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
